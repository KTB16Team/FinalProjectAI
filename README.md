# FinalProjectAI

AI ê¸°ë°˜ ì¤‘ì¬ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©ì í–‰ë™ ë¶„ë¥˜, ê°ì • ë¶„ì„, ê³µê° ì ìˆ˜ ì¸¡ì • ë“± ì„¸ ê°€ì§€ ì£¼ìš” ëª¨ë¸ì„ í†µí•©í•˜ì—¬ ê°ˆë“± ìƒí™©ì„ ë¶„ì„í•˜ê³  ê³¼ì‹¤ ë¹„ìœ¨ì„ ì‚°ì¶œí•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. 
ë³¸ ë¬¸ì„œëŠ” AI ëª¨ë¸ êµ¬ì¡°, ë°ì´í„° ì²˜ë¦¬ ë°©ì‹, í•™ìŠµ ê³¼ì •, ê·¸ë¦¬ê³  ëª¨ë¸ í†µí•© ë¡œì§ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---
# ğŸ§¶ í™ì—°(ç´…ç·£) - Aimo: AI ì¤‘ì¬ì

**â€œì¸ì—°ì„ ì´ì–´ì£¼ëŠ” ë¶‰ì€ ì‹¤â€**  
í™ì—°ì€ AI ê¸°ìˆ ì„ í†µí•´ ì‚¬ëŒë“¤ ê°„ ê°ˆë“±ì„ ë¶„ì„í•˜ê³ , í•´ê²° ë°©ì•ˆì„ ì œì‹œí•˜ëŠ” í˜ì‹ ì ì¸ ì¤‘ì¬ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ“– í”„ë¡œì íŠ¸ ê°œìš”

AimoëŠ” ìŒì„± ë° í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ AI ëª¨ë¸ë¡œ ë¶„ì„í•˜ì—¬ ê°ˆë“±ì˜ ì›ì¸ì„ íŒŒì•…í•˜ê³  ê³µì •í•œ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤.  
ì„œë¹„ìŠ¤ëŠ” **STT**, **OCR**, **ê°ˆë“± ë¶„ì„ AI ëª¨ë¸**ë¡œ êµ¬ì„±ë˜ë©°, ìµœì¢…ì ìœ¼ë¡œ ê° ì°¸ì—¬ìì˜ ê³¼ì‹¤ ë¹„ìœ¨ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.

---

## ğŸ§  AI ëª¨ë¸ ë¡œì§ ë° êµ¬í˜„

### **1. í–‰ë™ ë¶„ë¥˜ ëª¨ë¸**

- **íŒŒì¼**: `behavior_classification.py`
- **ê¸°ëŠ¥**: ì‚¬ìš©ìì˜ ëŒ€í™” ì†ì—ì„œ í–‰ë™ ìœ í˜•ì„ ë¶„ë¥˜í•˜ì—¬ ê°ˆë“±ì˜ êµ¬ì²´ì ì¸ ì›ì¸ì„ íŒŒì•…
- **ë¶„ë¥˜ ì¹´í…Œê³ ë¦¬**: ê²½ìŸí˜•/íšŒí”¼í˜•/ìˆ˜ìš©í˜•/íƒ€í˜‘í˜•/í˜‘ë ¥í˜•
- **config**:
  - MAX_LENGTH: 256
  - BATCH_SIZE: 16
  - EPOCHS: 10
  - LEARNING_RATE: 2e-5
  - NUM_LABELS: 5
  - PATIENCE: 5
  - WEIGHT_DECAY: 0.01
- **text augmentation**
  - EDA
    - ë‹¨ì–´ ì‚­ì œ, êµì²´, ì¶”ê°€, ìˆœì„œ ë³€ê²½
  - ìœ ì‚¬ ì„ë² ë”© ëŒ€ì²´
    - ë‹¨ì–´ ì„ë² ë”© ìœ ì‚¬ë„ ê¸°ë°˜ ëŒ€ì²´
  - Contetualized Embedding ëŒ€ì²´
    - ë¬¸ë§¥ ê¸°ë°˜ ë‹¨ì–´ ëŒ€ì²´
- **ğŸ“‚ ë°ì´í„°ì…‹ ì˜ˆì‹œ**:
  - ì´ 3,869ê°œ (ê²½ìŸí˜•:771ê°œ/íšŒí”¼í˜•:759ê°œ/ìˆ˜ìš©í˜•:786ê°œ/íƒ€í˜‘í˜•:767ê°œ/í˜‘ë ¥í˜•:786ê°œ) -> ì¦ê°• í›„ 21665ê°œ
ë¬¸ë§¥ ë° ê°ì • ì ìˆ˜ ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„°ì…‹(`behavior_dataset.json`)ì˜ ì¼ë¶€ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```json
{
    "behavior_examples": [
        {
            "category": "ê²½ìŸí˜•",
            "examples": [
                {"text": "ì´ê²Œ ë‹¤ ë„¤ê°€ ì œëŒ€ë¡œ ì¤€ë¹„ ì•ˆ í•´ì„œ ê·¸ëŸ° ê±° ì•„ë‹ˆì•¼?", "label": "ê²½ìŸí˜•"},
                {"text": "ë„¤ê°€ ì´ë ‡ê²Œ í•  ì¤„ ì•Œì•˜ì–´", "label": "ê²½ìŸí˜•"},
                {"text": "ì´ëŸ° ê¸°ë³¸ì ì¸ ê²ƒë„ ëª»í•˜ë©´ì„œ ë­˜ í•˜ê² ë‹¤ëŠ” ê±°ì•¼", "label": "ê²½ìŸí˜•"}
            ]
        },
        {
            "category": "í˜‘ë ¥í˜•",
            "examples": [
                {"text": "ìš°ë¦¬ ì´ ë¬¸ì œë¥¼ í•¨ê»˜ í•´ê²°í•´ ë³´ì.", "label": "í˜‘ë ¥í˜•"},
                {"text": "ë‹¤ìŒ ë²ˆì—” ë‚´ê°€ ë„ì™€ì¤„ê²Œ.", "label": "í˜‘ë ¥í˜•"},
                {"text": "ìš°ë¦¬ê°€ í˜ì„ í•©ì¹˜ë©´ ì˜ í•  ìˆ˜ ìˆì„ ê±°ì•¼.", "label": "í˜‘ë ¥í˜•"}
            ]
        }
    ]
}
```
- **í•µì‹¬ ë¡œì§**:
  ```python
  def classify_behavior(input_text: str):
      """
      í–‰ë™ ìœ í˜•ì„ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜
      Args:
          input_text (str): ì…ë ¥ í…ìŠ¤íŠ¸
      Returns:
          prediction (str): í–‰ë™ ìœ í˜• ì˜ˆì¸¡
      """
      model = torch.load("Behavior_classifier.pt")
      tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
      tokens = tokenizer(input_text, return_tensors="pt")
      output = model(**tokens)
      prediction = torch.argmax(output.logits, dim=-1)
      return prediction
  ```
  - **ì¶œë ¥**: í–‰ë™ ë¶„ë¥˜ ê²°ê³¼ (ex. ê²½ìŸí˜•)
---

### **2. ë¬¸ë§¥ ë° ê°ì • ì ìˆ˜ ëª¨ë¸**

- **íŒŒì¼**: `BERTbasedcontext.py`
- **ê¸°ëŠ¥**: ëŒ€í™”ì˜ ë¬¸ë§¥ê³¼ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ìƒí™©ì˜ ì‹¬ê°ì„±ì„ ì ìˆ˜í™”
- **text augmentation**
  - Random Insertion
    - ì„ì˜ì˜ ë‹¨ì–´ë¥¼ ë¬¸ì¥ ë‚´ì— ì‚½ì…í•˜ì—¬ ë¬¸ì¥ì˜ ë‹¤ì–‘ì„± ì¦ê°€
  - Add Noise
    - ë¬¸ì ìˆ˜ì¤€ì—ì„œ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•´ ëª¨ë¸ì˜ ê²¬ê³ ì„± í–¥ìƒ
- **ğŸ“‚ ë°ì´í„°ì…‹ ì˜ˆì‹œ**:
  - ì´ 943ê°œ -> ì¦ê°• í›„ 2829ê°œ
ë¬¸ë§¥ ë° ê°ì • ì ìˆ˜ ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„°ì…‹(`BERT-based_dataset.json`)ì˜ ì¼ë¶€ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```json
{
    "conversation_id": "conv_001",
    "utterances": [
        "ì—¬ë³´ì„¸ìš”? ë°©ê¸ˆ ë©´ì ‘ ê²°ê³¼ ì—°ë½ ë°›ì•˜ì–´ìš”!",
        "í—.. ë–¨ë ¤ì„œ ì‹¬ì¥ì´ í„°ì§ˆ ê²ƒ ê°™ì•„ìš”. ê·¼ë° ìµœì¢… í•©ê²©ì´ë˜ìš”!!",
        "ì•„... ê·¼ë° ì—°ë´‰ì´ ìƒê°ë³´ë‹¤ ë„ˆë¬´ ë‚®ê²Œ ì œì‹œëì–´ìš”."
    ],
    "emotions": [0.6, 0.9, 0.3],
    "context_labels": {
        "situation": "job_interview_result",
        "emotion_flow": "anticipation->joy->disappointment"
    }
}
```
- **í•µì‹¬ ë¡œì§**:
```python
 def analyze_emotion(input_text: str):
    """
    ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ê°ì • ì ìˆ˜ë¥¼ ë¶„ì„
    Args:
        input_text (str): ì…ë ¥ í…ìŠ¤íŠ¸
    Returns:
        emotion_score (float): ê°ì • ì ìˆ˜
    """
    model = torch.load("BERTbasedemotion_model.pt")
    tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
    tokens = tokenizer(input_text, return_tensors="pt")
    output = model(**tokens)
    emotion_score = torch.softmax(output.logits, dim=-1)[0, 1].item()
    return emotion_score
```
 - **ì¶œë ¥**: ê°ì • ì ìˆ˜ (0-1 ë²”ìœ„)
---

### **3. ê³µê° ì ìˆ˜ ì¸¡ì • ëª¨ë¸**

- **íŒŒì¼**: 'empathy_data_preprocessig.py', `empathy_score.py.py`
- **ê¸°ëŠ¥**: ëŒ€í™”ì—ì„œ ìƒëŒ€ë°©ì— ëŒ€í•œ ê³µê°ì„ ì ìˆ˜í™”í•˜ì—¬ í˜‘ë ¥ ê°€ëŠ¥ì„± í‰ê°€
- **text augmentation**
  - Random deletion
    - ë¬¸ì¥ì—ì„œ ì„ì˜ì˜ ë‹¨ì–´ ì‚­ì œ
  - Random swap
    - ë¬¸ì¥ ë‚´ ì„ì˜ì˜ ë‘ë‹¨ì–´ì˜ ìœ„ì¹˜ë¥¼ êµí™˜í•˜ì—¬ ë¬¸ì¥ì˜ êµ¬ì¡° ë³€í˜•
  - Random insertion
    - ë¬¸ì¥ ë‚´ ì„ì˜ì˜ ìœ„ì¹˜ì— ë‹¨ì–´ ì‚½ì…í•˜ì—¬ ë‹¤ì–‘ì„± ì¦ê°€ì‹œí‚´
  - Synonym replacement
    - initì—ì„œ í•œêµ­ì–´ ë‹¨ì–´ì™€ ìœ ì‚¬ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ì „ í˜•íƒœë¡œ ì €ì¥í•¨
    - ë‹¨ìˆœ ì‚¬ì „ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ìœ ì‚¬ì–´ë¡œ ì¹˜í™˜í•˜ì—¬ ë¬¸ì¥ì˜ ì˜ë¯¸ ë³´ì¡´í•´ ë‹¤ì–‘ì„± ì¦ê°€
  - Noise Injection
    - í…ìŠ¤íŠ¸ì— ë…¸ì´ì¦ˆ ì£¼ì…í•´ ê²¬ê³ ì„± í–¥ìƒì‹œí‚´
  - Augment text
    - ì—¬ëŸ¬ ì¦ê°• ê¸°ë²• ì¡°í•©í•´ í…ìŠ¤íŠ¸ ë³€í˜•
- **ğŸ“‚ ë°ì´í„°ì…‹ ì˜ˆì‹œ**:
 - ì›ë³¸ ë°ì´í„° í¬ê¸°: 2,692ê°œ ëŒ€í™” -> ì¦ê°• í›„ ë°ì´í„° í¬ê¸°: 14787
ë¬¸ë§¥ ë° ê°ì • ì ìˆ˜ ëª¨ë¸ì—ì„œ ì‚¬ìš©ëœ ë°ì´í„°ì…‹(`empathy_dataset.json`)ì˜ ì¼ë¶€ ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

```json
{
    "dialogue_id": "001",
    "utterances": [
        {
            "utterance_id": "001_1",
            "speaker": "A",
            "text": "ìê¸°ì•¼, ì˜¤ëŠ˜ ê¸°ë¶„ ì–´ë•Œ?",
            "emotion": "ì¤‘ë¦½",
            "empathy_score": 0.0
        },
        {
            "utterance_id": "001_2",
            "speaker": "B",
            "text": "íšŒì‚¬ì—ì„œ ì‹¤ìˆ˜í•´ì„œ íŒ€ì¥ë‹˜í•œí…Œ í˜¼ë‚¬ì–´... ë§ì´ ì†ìƒí•´",
            "emotion": "ìŠ¬í””",
            "empathy_score": 0.0
        },
        {
            "utterance_id": "001_3",
            "speaker": "A",
            "text": "ë§ì´ í˜ë“¤ì—ˆê² ë‹¤... ìš°ë¦¬ ìê¸°ê°€ í‰ì†Œì— ì–¼ë§ˆë‚˜ ì—´ì‹¬íˆ í•˜ëŠ”ë°. ì €ë…ì— ë§›ìˆëŠ” ê±° ë¨¹ìœ¼ëŸ¬ ê°ˆê¹Œ?",
            "emotion": "ê³µê°",
            "empathy_score": 0.9
        }
    ]
}
```
- **í•µì‹¬ ë¡œì§**:
```python
def compute_empathy_score(dialogues: List[str]):
    """
    ëŒ€í™”ì˜ ê³µê° ì ìˆ˜ë¥¼ ê³„ì‚°
    Args:
        dialogues (List[str]): ëŒ€í™” ë¦¬ìŠ¤íŠ¸
    Returns:
        empathy_score (float): ê³µê° ì ìˆ˜
    """
    model = torch.load("bestmodel.pt")
    features = preprocess_dialogues(dialogues)
    output = model(features)
    empathy_score = torch.mean(output.logits).item()
    return empathy_score
```
 - **ì¶œë ¥**: ê³µê° ì ìˆ˜ (0-1 ë²”ìœ„)
---

### **4. ëª¨ë¸ í†µí•© ë° ê³¼ì‹¤ ë¹„ìœ¨ ì‚°ì¶œ**

- **íŒŒì¼**: 'score_multi.py'
- **ê¸°ëŠ¥**: 3ê°œì˜ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ê³¼ì‹¤ ë¹„ìœ¨ ì‚°ì¶œ
- **í•µì‹¬ ë¡œì§**: ìƒí™© ë¶„ì„ ë° ìš”ì•½ -> í–‰ë™ ë¶„ë¥˜ -> ë¬¸ë§¥ ê°ì • -> ê³µê° ì ìˆ˜ -> ìµœì¢… íŒê²°ë¬¸ ì¶œë ¥ 
- **ìƒí™© ë¶„ì„** (SituationAnalyzer)
  - ê¸°ëŠ¥: ê°ˆë“± í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ìƒí™©ê³¼ ê° ìƒí™©ì˜ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•˜ê³  ê´€ë ¨ ë¬¸ì¥ ì¶”ì¶œ
  - ì£¼ìš” ê°ˆë“± ìƒí™©ê³¼ ì¤‘ìš”ë„ ë¶„ì„
    - ê´€ë ¨ ë¬¸ì¥ ë¹ˆë„(frequency_score): ë¬¸ì¥ì—ì„œ í‚¤ì›Œë“œì™€ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨
    - ê°ì • ì¤‘ìš”ë„(emotion_importance): ê´€ë ¨ ë¬¸ì¥ì˜ ê°ì • ì ìˆ˜ í‰ê· ã„´
```python
class SituationAnalyzer:
    async def analyze_text(self, text: str) -> Dict[str, Dict[str, any]]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” ê°ˆë“± ìƒí™©ê³¼ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
        Args:
            text (str): ì…ë ¥ í…ìŠ¤íŠ¸
        Returns:
            Dict: ìƒí™©ë³„ ì¤‘ìš”ë„ì™€ ê´€ë ¨ ë¬¸ì¥
        """
        prompt = f"""Analyze the following text:
        Text: {text}

        Please respond in the following JSON format:
        {{
            "situations": [
                {{
                    "category": "situation category name",
                    "importance": importance of the situation (0 to 1),
                    "related_sentences": ["sentence 1", "sentence 2"]
                }},
                ...
            ]
        }}"""

        response = await self.client.chat.completions.create(
            model=Config.GPT_MODEL,
            messages=[
                {"role": "system", "content": "You are an expert at analyzing conflict situations."},
                {"role": "user", "content": prompt}
            ]
        )
        analysis = json.loads(response.choices[0].message.content)
        return {
            s["category"]: {
                "importance": s["importance"],
                "sentences": s["related_sentences"]
            } for s in analysis["situations"]
        }

```

- **í–‰ë™ ë¶„ë¥˜ ë° ì ìˆ˜ ë§¤í•‘ (Behavior_classification)**
  - í´ë˜ìŠ¤: CustomBERTClassifier
  - í–‰ë™ ì ìˆ˜ ë§¤í•‘
      ```python
      def map_category_score(category):
    score_map = {
        "ê²½ìŸ": 0,
        "íšŒí”¼": 0,
        "íƒ€í˜‘": 0.5,
        "í˜‘ë ¥": 1,
        "ìˆ˜ìš©": 1
    }
    return score_map.get(category, 0)
    ```
- **ê°ì • ë¶„ì„ (Emotion Analysis)**
  - í´ë˜ìŠ¤: SentenceEmotionAnalyzer
- **ê³¼ì‹¤ ë¹„ìœ¨ ê³„ì‚° (Fault Ratio Calculation)**
  - ConflictAnalyzer
  - ê¸°ëŠ¥: ê°ì • ì ìˆ˜, í–‰ë™ ì ìˆ˜, ìƒí™© ì¤‘ìš”ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›ê³ ì™€ í”¼ê³ ì˜ ê³¼ì‹¤ ë¹„ìœ¨ì„ ê³„ì‚°
  - í•µì‹¬ ë¡œì§
    ```python
    async def analyze_content(self, content: str) -> dict:
    """
    í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ê³¼ì‹¤ ë¹„ìœ¨ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    Args:
        content (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
    Returns:
        dict: ë¶„ì„ ê²°ê³¼
    """
    situation_data = await self.situation_analyzer.analyze_text(content)
    speaker_scores = {"plaintiff": 0, "defendant": 0}

    for situation, data in situation_data.items():
        sentences = data["sentences"]
        importance = data["importance"]

        emotion_scores = self.emotion_analyzer.analyze_sentences(sentences)
        behavior_scores = predict_category_scores(
            sentences, self.behavior_model, self.tokenizer, self.label_map, self.device
        )

        for e_score, b_score in zip(emotion_scores, behavior_scores):
            score = e_score * b_score * importance
            speaker_scores["plaintiff" if "ë‚´ê°€" in sentences else "defendant"] += score

    total_score = sum(speaker_scores.values())
    fault_rate = round((speaker_scores["plaintiff"] / total_score) * 100, 2) if total_score else 50.0
    return {"plaintiff_fault_rate": fault_rate}
    ```

---
## ğŸ™ï¸ STT ë° OCR ë°ì´í„° ì²˜ë¦¬

### **1. STT (Speech-to-Text)**

- **íŒŒì¼**: 'audio_process.py', 'download_s3_file.py'
- **ì‚¬ìš©ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬**: OpenAI Whisper, Boto3
- **ì—”ë“œ í¬ì¸íŠ¸**: /speech-to-text
- **ê¸°ëŠ¥**: S3ì— ì €ì¥ëœ ìŒì„± íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
- **í•µì‹¬ ë¡œì§**:
 ```python
  async def download_s3_file(url):
      """
      AWS S3ì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
      Args:
          url (str): S3 ê°ì²´ URL
      Returns:
          str: ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ì˜ ê²½ë¡œ
      """
      bucket_name, object_key, filename = await parse_s3_url(url)
      temp_dir = "temp"
      os.makedirs(temp_dir, exist_ok=True)

      s3_client.download_file(bucket_name, object_key, temp_file_path)
      if os.path.exists(temp_file_path):
          logger.info(f"File downloaded successfully: {temp_file_path}")
      else:
          raise FileNotFoundError("Downloaded file not found")
      return temp_file_path

 async def transcribe_audio(file_path):
    """
    ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Args:
        file_path (str): ìŒì„± íŒŒì¼ ê²½ë¡œ
    Returns:
        str: ë³€í™˜ëœ í…ìŠ¤íŠ¸
    """
    client = OpenAI(api_key=settings.OPENAI_API_KEY)
    with open(file_path, "rb") as audio_file:
        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file
        )
    return transcription.text
 ```

### **2. OCR (Optical Character Recognition)**

- **íŒŒì¼**: 'audio_process.py', 'download_s3_file.py'
- **ì‚¬ìš©ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬**: EasyOCR, OpenCV
- **ì—”ë“œ í¬ì¸íŠ¸**: /image-to-text
- **ê¸°ëŠ¥**: S3ì— ì €ì¥ëœ ìŒì„± íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜.
- **í•µì‹¬ ë¡œì§**:
  ```python
  async def extract_text_from_image(image_path):
      """
      ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
      Args:
          image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
      Returns:
          list[dict]: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì™€ í™•ë¥  ì •ë³´ê°€ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸
      """
      # EasyOCR ë¦¬ë” ê°ì²´ ìƒì„±
      reader = easyocr.Reader(['ko', 'en'])
      
      # ì´ë¯¸ì§€ íŒŒì¼ ì½ê¸°
      image = cv2.imread(image_path)
      if image is None:
          raise FileNotFoundError(f"Image file not found: {image_path}")

      # í…ìŠ¤íŠ¸ ì¶”ì¶œ
      results = reader.readtext(image)

      # ê²°ê³¼ í¬ë§·íŒ…
      extracted_texts = []
      for bbox, text, prob in results:
          extracted_texts.append({
              "text": text,
              "probability": prob,
              "bounding_box": bbox
          })
      return extracted_texts
    ```
---
## Async Processing in Mediation Service

### **ì£¼ìš” ë¹„ë™ê¸° ì²˜ë¦¬ íë¦„**
- **RabbitMQ ê¸°ë°˜ ë¹„ë™ê¸° ì²˜ë¦¬**
  - ê¸°ëŠ¥: RabbitMQ ë©”ì‹œì§€ íë¥¼ ì‚¬ìš©í•˜ì—¬ AI ëª¨ë¸ì„ í˜¸ì¶œí•˜ê³  ê²°ê³¼ ì²˜ë¦¬
  - í•µì‹¬ ë¡œì§:
  ```python
  def process_message(ch, method, properties, body):
    """
    RabbitMQ ë©”ì‹œì§€ ì²˜ë¦¬ ì½œë°± í•¨ìˆ˜.
    Args:
        ch: ì±„ë„
        method: ë©”ì‹œì§€ ì „ë‹¬ ì •ë³´
        properties: ë©”ì‹œì§€ ì†ì„±
        body: ë©”ì‹œì§€ ë³¸ë¬¸
    """
    try:
        message = json.loads(body.decode('utf-8'))
        content = message.get("content")
        request_id = message.get("id")

        if not content or not request_id:
            raise ValueError("Invalid message: Missing 'content' or 'id'")

        execute_score_multi_and_callback(content, request_id)
        ch.basic_ack(delivery_tag=method.delivery_tag)

    except Exception as e:
        logger.error(f"Error processing message: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
  ```

- **BackgroundTasks ì²˜ë¦¬**
  - ê¸°ëŠ¥: FastAPI BackgroundTasksë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ì ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ê³  ì½œë°± URLì— POST ìš”ì²­
  - í•µì‹¬ ë¡œì§:
```python
  @router.post("/judgement", status_code=202)
async def process_judge(request: JudgeRequest, background_tasks: BackgroundTasks):
    """
    ìš”ì²­ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  202 Accepted ì‘ë‹µ ë°˜í™˜.
    Args:
        request (JudgeRequest): ìš”ì²­ ë°ì´í„°
        background_tasks (BackgroundTasks): ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ê´€ë¦¬ ê°ì²´
    Returns:
        dict: ì‘ë‹µ ìƒíƒœ
    """
    background_tasks.add_task(execute_test_response_and_callback, request.content, request.id)
    return {"status": "accepted", "message": "Judgement processing started."}
```

---
## ğŸ› ï¸ì‚¬ìš© ê¸°ìˆ  
- AI ë° NLP
  - OpenAI GPT-4
  - Hugging Face Transformers
    - BERT ê¸°ë°˜ ê°ì • ë¶„ì„ ëª¨ë¸
    - BERT ê¸°ë°˜ í–‰ë™ ë¶„ë¥˜ ëª¨ë¸
  - PyTorch
- ìŒì„± ë° ì´ë¯¸ì§€ ì²˜ë¦¬
  - OpenAI Whisper
  - EasyOCR
- ë°±ì—”ë“œ ë° API
  - FastAPI
    - ê³ ì„±ëŠ¥ ë¹„ë™ê¸° API ì„œë²„
  - HTTPx
    - ë¹„ë™ê¸° HTTP clientë¡œ ì™¸ë¶€ API í†µì‹ 
  - pika
    - RabbitMQ ë©”ì„¸ì§€ í ê´€ë¦¬ ë° ì‘ì—… ë¶„ë°°
  - ë°ì´í„° ê´€ë¦¬ ë° í´ë¼ìš°ë“œ
    - AWS S3
      - ìŒì„± ë° ì´ë¯¸ì§€ ë°ì´í„° ì €ì¥ ë° ê´€ë¦¬
## ğŸ“® ë¬¸ì˜

- íŒ€ GitHub: [KTB16Team](https://github.com/KTB16Team)
- ê´€ë ¨ ë¬¸ì˜ëŠ” Issuesë¥¼ í†µí•´ ë‚¨ê²¨ì£¼ì„¸ìš”.
